---
layout: post
title:  "【60天重学左耳】Day33-性能设计篇之“边缘计算”"
date:   2020-01-17 23:00:00 +0800
categories: code
tags: [Distributed]
author: 方伟
---

打卡Day33：今天学习了《62｜性能设计篇之“边缘计算”》，我的收获如下：

1. 边缘计算：不一定是和IoT相关，它是对于数据中心而言。数据中心把所有服务放在一个机房里集中处理用户的数据和请求，集中式部署一方面便于管理和运维，另一方面也便于服务间的通讯有一个比较好的网络保障。基于CDN让这些边缘节点拥有可定制的计算能力。
2. 为什么要有边缘计算：整个计算机发展的本质就是我们人类生活信息化建设的过程。MB 时代（服务商提供内容：新闻资讯）=> GB时代（用户产生内容UGC：文字、图片、视频）=> TB时代（大数据：收集用户信息）=> PB时代（AT、IoT）。数据量越来越大，分析结果的速度需要越来越快，这两个需求，只会把我们逼到边缘计算上去。 如果你还是在数据中心处理，你会发现你的成本只会越来越高，到一定时候就完全玩不下去了。
3. 当需要处理的数据或是用户请求的规模越来越大时，我们的成本是呈现快速上升的曲线，而不是一个线性上升的成本关系。几十万用户，百级QPS，10台服务器 => 上百万用户，千级QPS，50台服务器 => 上千万用户，万级到十万级QPS，700台服务器 => 上亿用户，百万级QPS，上万台服务器。当架构变复杂了后，就要做很多非功能的东西了，比如，缓存、队列、服务发现、网关、自动化运维、监控等。
4. 关于降低成本的脑洞：如果能够把那上亿的用户拆成100个百万级的用户，只需要5000多台机器（100个50台服务器的数据中心）。同样服务了这么多的用户，但成本下降得很快。运维100个50台服务器的小数据中心的难度应该远远低于运维一个10000台服务器的数据中心。有地域性的业务是可以这么做的，比如：外卖、叫车、共享单车之类的。但是，有100万用户的时候的业务形态和有1亿用户的业务形态是完全不一样的，1亿用户的业务形态可能会复杂得多得多。也就是说，我们不可能在一个小数据中心只有50台服务器，因为那是百万用户的业务形态，只有几十个服务。当公司成长到上亿用户的规模时，可能会有上百个服务，50台服务器是不够部署的。所以，我上面那种多个数据中心的理想只存在于理论上，而实际上不会发生。沿着这条路思考下去，可以用边缘结点处理高峰流量，这样数据中心就不需要花那么大的成本来建设了。于是，还是到了边缘计算。
5. 边缘计算的业务场景：处理一些实时响应的业务（人脸门禁、共享单车开锁）；处理一些简单的业务逻辑（秒杀、红包）；收集并结构化数据（识别视频中车牌）；实时设备监控（线下数据采集）；P2P去中心化应用（服务发现）；云资源调度（流量接入调度）；云资源聚合（语音转文字和语义识别API聚合）。
6. 边缘计算的关键技术：API Gateway；Serverless/FaaS（源于2012年Ken Form《Why The Future of Software and Apps is Serverless》）。Serverless架构可以提供一种更加"代码碎片化"的软件架构范式，我们称之为Function as a Services（FaaS）。所谓的“函数”（Function）提供的是相比微服务更加细小的程序单元。
7. Serverless开源项目：Serverless Framework；Fission: Serverless Functions for Kubernetes；Open Lambda；Open FaaS；IronFunction。

> [左耳朵耗子带你重学《左耳听风》](https://time.geekbang.org/column/article/177414?utm_term=zeusL3AA0&utm_source=wechat&utm_medium=chongxuedaka)


